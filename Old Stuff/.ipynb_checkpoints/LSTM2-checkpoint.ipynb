{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_data.csv',index_col=None,header=0)\n",
    "data = data[['id','depth','parent_id','score','lemmatized','lemm_sub','sentiment','subjectivity','sentiment_sub','subjectivity_sub','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['labels'] == 'supporting', 'labels'] = 0\n",
    "data.loc[data['labels'] == 'denying', 'labels'] = 1\n",
    "data.loc[data['labels'] == 'questioning', 'labels'] = 2\n",
    "data.loc[data['labels'] == 'commenting', 'labels'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>depth</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>lemm_sub</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment_sub</th>\n",
       "      <th>subjectivity_sub</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4xury6</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_4r2tl4</td>\n",
       "      <td>31</td>\n",
       "      <td>no question want thank post topic birth contro...</td>\n",
       "      <td>updated september scroll downhi lengthy post c...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4yi9y9</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_4r2tl4</td>\n",
       "      <td>7</td>\n",
       "      <td>holy shit thank much someone recently turn sup...</td>\n",
       "      <td>updated september scroll downhi lengthy post c...</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d4yhm4h</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_4r2tl4</td>\n",
       "      <td>7</td>\n",
       "      <td>people nice friendly super non judgmental espe...</td>\n",
       "      <td>updated september scroll downhi lengthy post c...</td>\n",
       "      <td>0.189815</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4y5kmd</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_4r2tl4</td>\n",
       "      <td>3</td>\n",
       "      <td>thanks post tried yaz oral contraceptive prior...</td>\n",
       "      <td>updated september scroll downhi lengthy post c...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d4y8tvk</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_4r2tl4</td>\n",
       "      <td>3</td>\n",
       "      <td>minor need show parent consent</td>\n",
       "      <td>updated september scroll downhi lengthy post c...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.114394</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  depth  parent_id  score  \\\n",
       "0  d4xury6      0  t3_4r2tl4     31   \n",
       "1  d4yi9y9      0  t3_4r2tl4      7   \n",
       "2  d4yhm4h      0  t3_4r2tl4      7   \n",
       "3  d4y5kmd      0  t3_4r2tl4      3   \n",
       "4  d4y8tvk      0  t3_4r2tl4      3   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  no question want thank post topic birth contro...   \n",
       "1  holy shit thank much someone recently turn sup...   \n",
       "2  people nice friendly super non judgmental espe...   \n",
       "3  thanks post tried yaz oral contraceptive prior...   \n",
       "4                     minor need show parent consent   \n",
       "\n",
       "                                            lemm_sub  sentiment  subjectivity  \\\n",
       "0  updated september scroll downhi lengthy post c...   0.333333      0.416667   \n",
       "1  updated september scroll downhi lengthy post c...   0.104167      0.308333   \n",
       "2  updated september scroll downhi lengthy post c...   0.189815      0.540741   \n",
       "3  updated september scroll downhi lengthy post c...   0.133333      0.133333   \n",
       "4  updated september scroll downhi lengthy post c...  -0.050000      0.200000   \n",
       "\n",
       "   sentiment_sub  subjectivity_sub  labels  \n",
       "0       0.114394          0.533718       0  \n",
       "1       0.114394          0.533718       0  \n",
       "2       0.114394          0.533718       3  \n",
       "3       0.114394          0.533718       0  \n",
       "4       0.114394          0.533718       2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(data['labels'], num_classes=4)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_most_common_words = 8000\n",
    "max_len = 2000\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(data['lemmatized'].values)\n",
    "sequences = tokenizer.texts_to_sequences(data['lemmatized'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "emb_dim = 128\n",
    "batch_size = 256\n",
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "model.add(LSTM(64, dropout=0.7, recurrent_dropout=0.7))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 3s 10ms/step\n",
      "Test set\n",
      "  Loss: 1.263\n",
      "  Accuracy: 0.495\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24165025 0.14786114 0.17905003 0.4314386 ]] commenting\n"
     ]
    }
   ],
   "source": [
    "txt = [\"terrible\"]\n",
    "seq = tokenizer.texts_to_sequences(txt)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "labels = ['supporting', 'denying', 'questioning', 'commenting']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
